

# 数据操作+数据预处理

## 1 使用切片访问矩阵内的元素

### 1.1 访问单个元素

<img src="https://img-blog.csdnimg.cn/64dd0ac76663485a8ab3274fdafa1c62.png" style="zoom: 33%;" />

### 1.2 访问一行元素

<img src="https://img-blog.csdnimg.cn/cf26074554304717ae213ee3694f242e.png" style="zoom:33%;" />

### 1.3 访问子区域

<img src="https://img-blog.csdnimg.cn/22f23c7eaf9949498c2043f541221674.png" style="zoom:33%;" />

==[1:3]==代表从第一行到第二行(**左闭右开的区间**)；==[1::]==代表访问包括第一列之后的所有列；



### 1.4 访问离散的子区域

<img src="https://img-blog.csdnimg.cn/e8503b5722aa46498c78b5048730b6e5.png" style="zoom:33%;" />

==a[::3,::2]==表示在矩阵中选取每隔 3 行和每隔 2 列的元素



## 2 Pytorch基本操作

==补充知识点：标量是0维张量，向量是1维张量，矩阵是2维张量。==

### 2.1 基于张量的基本操作

#### `torch.range()`

使用 `arange` 创建一个行向量 `x`。这个行向量包含以0开始的前12个整数，它们默认创建为整数。也可指定创建类型为浮点数。张量中的每个值都称为张量的 *元素*（element）。例如，张量 `x` 中有 12 个元素。除非额外指定，新的张量将存储在内存中，并采用基于CPU的计算。

````python
import torch
x = torch.arange(12)
print(x)
````

运行结果：

> tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])



#### `x.shape`

访问张量（沿每个轴的长度）的*形状* 。

```python
import torch
x = torch.arange(12)
print(x.shape)
```

运行结果：

> torch.Size([12])



#### `x.numel()`

即**Number of elements**，获取张量中元素的总数。

```python
import torch
x = torch.arange(12)
print(x.numel())
```

运行结果：

> 12



#### `x.reshape()`

改变一个张量的形状而不改变元素数量和元素值，可以调用`reshape`函数。 例如，可以把张量`x`从形状为（12,）的行向量转换为形状为（3,4）的矩阵。 这个新的张量包含与转换前相同的值，但是它被看成一个3行4列的矩阵。

```python
import torch
x = torch.arange(12)
print(x)
x = x.reshape(4, 3)
print(x)
```

运行结果：

> tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])
> tensor([[ 0,  1,  2],
>         [ 3,  4,  5],
>         [ 6,  7,  8],
>         [ 9, 10, 11]])



在上面的例子中，为了获得一个3行的矩阵，我们手动指定了它有3行和4列。 幸运的是，我们可以通过`-1`来调用**自动计算维度**的功能。 即我们可以用`x.reshape(-1,4)`或`x.reshape(3,-1)`来取代`x.reshape(3,4)`。

```python
import torch
x = torch.arange(12)
print(x)
x = x.reshape(-1, 4)
print(x)
x = x.reshape(6, -1)
print(x)
```



运行结果：

> tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])
> tensor([[ 0,  1,  2,  3],
>         [ 4,  5,  6,  7],
>         [ 8,  9, 10, 11]])
> tensor([[ 0,  1],
>         [ 2,  3],
>         [ 4,  5],
>         [ 6,  7],
>         [ 8,  9],
>         [10, 11]])



#### `torch.zeros()/torch.ones()`

创建一个形状为`（2,3,4）`的张量，其中所有元素都设置为`0`。`（2,3,4）`表示2个3行4列的二维数组组成的三维数组。

```python
import torch
x = torch.zeros((2,3,4))	//所有元素设置为0，注意中间要用个括号来表示矩阵
print(x)
y = torch.ones((2,3,4))	//所有元素设置为1
print(y)
```

运行结果：

<img src="https://img-blog.csdnimg.cn/5b1173c4d7464e6f9c67fc2cde87724c.png" style="zoom:50%;" />



#### `torch.randn()`

有时我们想通过从某个特定的概率分布中随机采样来得到张量中每个元素的值。 例如，当我们构造数组来作为神经网络中的参数时，我们通常会随机初始化参数的值。 以下代码创建一个形状为`（3,4）`的张量。 其中的每个元素都从均值为0、标准差为1的标准高斯分布（正态分布）中随机采样。

```python
import torch
x = torch.randn(3, 4)
print(x)
```

运行结果：

>tensor([[ 0.7277, -1.3848, -0.2607,  0.9701],
>        [-2.3290, -0.3754,  0.2457,  0.0760],
>        [-1.2832, -0.3600, -0.3321,  0.8184]])



#### **嵌套列表**

通过提供包含数值的Python列表（或嵌套列表），来为所需张量中的每个元素赋予确定值。

```python
import torch
x = torch.tensor([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]]) //这个张量有3行4列，第一个维度的长度为3，第二个维度的长度为4
print(x)
```

运行结果：

> tensor([[2, 1, 4, 3],
>         [1, 2, 3, 4],
>         [4, 3, 2, 1]])



### 2.2 运算符

#### 基本算数运算符

对于任意具有相同形状的张量， 常见的标准算术运算符（`+`、`-`、`*`、`/`和`**`）都可以被升级为按元素运算。 我们可以在同一形状的任意两个张量上调用按元素操作。

```python
import torch
x = torch.tensor([1.0, 2, 4, 8])
y = torch.tensor([2, 2, 2, 2])
print(x + y, x - y, x * y, x / y, x ** y)    # **运算符是求幂运算
```

输出结果：

> (tensor([ 3.,  4.,  6., 10.]),
>  tensor([-1.,  0.,  2.,  6.]),
>  tensor([ 2.,  4.,  8., 16.]),
>  tensor([0.5000, 1.0000, 2.0000, 4.0000]),
>  tensor([ 1.,  4., 16., 64.]))



#### `torch.exp()`

```python
import torch
x = torch.tensor([1.0, 2, 4, 8])
torch.exp(x)
print(x)
```

输出结果：

> tensor([2.7183e+00, 7.3891e+00, 5.4598e+01, 2.9810e+03])



### 2.3







































