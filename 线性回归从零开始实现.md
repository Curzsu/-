 

## 1 生成数据集

我们将根据带有噪声的线性模型构造一个人造数据集，并使用这个有限样本的数据集来恢复这个模型的参数。在下面的代码中，我们生成一个包含**1000**个样本的数据集，每个样本包含从标准正态分布中采样的**2个特征**。
我们的合成数据集是一个矩阵$\mathbf{X}\in \mathbb{R}^{1000 \times 2}$。

我们使用线性模型参数$\mathbf{w} = [2, -3.4]^\top$、$b = 4.2$ 和噪声项$\epsilon$生成数据集及其标签：
$$
\mathbf{y}= \mathbf{X} \mathbf{w} + b + \mathbf\epsilon.
$$


$\epsilon$可以视为模型预测和标签时的潜在观测误差，在这里我们认为标准假设成立，即$\epsilon$服从均值为0的正态分布。为了简化问题，我们将标准差设为0.01。

下面的代码生成了一个包含噪声的线性数据集：

```python
import random
import torch
from d2l import torch as d2l

def synthetic_data(w, b, num_examples): # 接受三个参数：权重w、偏差b和样本数
    """生成y=Xw+b+噪声"""
    X = torch.normal(0, 1, (num_examples, len(w)))
    y = torch.matmul(X, w) + b	# y=Xw+b
    y += torch.normal(0, 0.01, y.shape)
    return X, y.reshape((-1, 1))

true_w = torch.tensor([2, -3.4])
true_b = 4.2
features, labels = synthetic_data(true_w, true_b, 1000)

print('features:', features[0],'\nlabel:', labels[0])

d2l.set_figsize()	
d2l.plt.scatter(features[:, 1].detach().numpy(), labels.detach().numpy(), 1);	# 画x的第二个特征与y(label)关系的散点图

d2l.plt.show()  
```

`y` 张量中的每一行都是一个预测结果。在你提供的代码中，`y` 是通过计算 `y = torch.matmul(X, w) + b` 得到的，其中 `X` 是特征张量，`w` 是权重张量，`b` 是偏差标量。这个计算过程表示对每个样本进行线性回归预测。

`d2l.plt.scatter` 函数的第一个参数和第二个参数分别表示散点图中每个点的 x 坐标和 y 坐标。这两个参数应该具有相同的形状。

在你提供的代码中，`features[1, :].detach().numpy()` 返回的是 `features` 张量的第二行，它是一个一维数组。而 `labels.detach().numpy()` 返回的是一个形状为 `(1000, 1)` 的二维数组。由于这两个数组的形状不同，所以会报错。

这是一段Python代码，它使用PyTorch库。下面是代码的逐行解释：

`X = torch.normal(0, 1, (num_examples, len(w)))`：`num_examples`表示生成的样本数，`len(w)`表示每个样本的特征数（列数就是特征数，行数是样本数）。这句代码生成了一个形状为`(num_examples, len(w))`的张量`X`，其中每个元素都是从均值为0、标准差为1的正态分布中随机采样得到的。

详细来说，第一个参数0表示生成的样本的均值为0，第二个参数1表示生成的样本的标准差为1。其中，均值和标准差都是正态分布的两个参数，用于描述正态分布的形态。均值决定了正态分布的中心位置，标准差决定了正态分布的形状。

- `y = torch.matmul(X, w) + b`：计算y=Xw+b，其中w是权重，b是偏差。

`torch.matmul`函数是PyTorch中的一个矩阵乘法函数，用于计算两个张量的矩阵乘积。如果两个张量都是一维的，则返回它们的点积运算结果（标量）；如果两个张量都是二维的，则返回它们的矩阵乘积结果；如果两个张量都是高维的，则返回它们的批矩阵乘积结果。

- `y += torch.normal(0, 0.01, y.shape)`：给y添加一些噪声，使其更接近真实数据。

这句代码的意思是将一个张量y加上一个均值为0，标准差为0.01的正态分布噪声。这种噪声通常被用于模型训练中，以增加模型的鲁棒性和泛化能力。

- `return X, y.reshape((-1, 1))`：返回X和y的张量形状。

这句代码的意思是将一个二维张量y按照指定的形状进行重塑。在这里，(-1, 1)表示将y重塑为一个列向量，其中-1表示自动计算行数，1表示列数为1。这样做的目的是将y转换为一个列向量，以便后续计算。

- `true_w = torch.tensor([2, -3.4])`：定义一个真实权重向量true_w。

- `true_b = 4.2`：定义一个真实偏差true_b。

- `features, labels = synthetic_data(true_w, true_b, 1000)`：生成包含1000个样本的数据集features和labels。

- `print('features:', features[0],'\nlabel:', labels[0])`：打印features和labels中的第一个样本。注意，`features`中的每一行都包含一个二维数据样本， `labels`中的每一行都包含一维标签值（一个标量）。

在PyTorch中，可以使用`len()`函数来获取张量的长度。对于张量，长度是指张量的第一个维度的大小。例如，对于一个形状为`(3, 4)`的张量，它的长度为`3`。如果你想获取张量的形状，可以使用`.shape`或`.size()`方法¹⁸。

输出结果：

> features: tensor([-0.5553,  0.3685]) 
> label: tensor([1.8242])

<img src="https://img-blog.csdnimg.cn/71df4af8bc1f45a2a824d62a8d39e2cc.png" style="zoom: 67%;" />

<center>通过生成第二个特征`features[:, 1]`和`labels`的散点图， 可以直观观察到两者之间的线性关系</center>



## 2 读取数据集

回想一下，训练模型时要对数据集进行遍历，每次抽取一小批量样本，并使用它们来更新我们的模型。 由于这个过程是训练机器学习算法的基础，所以有必要定义一个函数， 该函数能打乱数据集中的样本并以小批量方式获取数据。

在下面的代码中，我们[**定义一个`data_iter`函数， 该函数接收批量大小、特征矩阵和标签向量作为输入，生成大小为`batch_size`的小批量**]。 每个小批量包含一组特征和标签。

```py
import random
import matplotlib.pyplot as plt
import torch
from d2l import torch as d2l

def synthetic_data(w, b, num_examples):
    """生成y=Xw+b+噪声"""
    X = torch.normal(0, 1, (num_examples, len(w)))
    y = torch.matmul(X, w) + b
    y += torch.normal(0, 0.01, y.shape)
    return X, y.reshape((-1, 1))

true_w = torch.tensor([2, -3.4])
true_b = 4.2
features, labels = synthetic_data(true_w, true_b, 1000)

# print('features:', features[0],'\nlabel:', labels[0])

"""接收批量大小、特征矩阵和标签向量作为输入，生成大小为batch_size的小批量"""
def data_iter(batch_size, features, labels):
    num_examples = len(features)
    indices = list(range(num_examples))
    # 这些样本是随机读取的，没有特定的顺序
    random.shuffle(indices)
    for i in range(0, num_examples, batch_size):
        batch_indices = torch.tensor(
            indices[i: min(i + batch_size, num_examples)])
        yield features[batch_indices], labels[batch_indices]

batch_size = 10

for X, y in data_iter(batch_size, features, labels):
    print(X, '\n', y)
    break

```



输出结果：

> tensor([[ 0.9732, -0.1939],
>         [-2.0049,  0.7813],
>         [-2.3117,  0.2255],
>         [ 0.0397,  0.4737],
>         [ 1.4415,  0.2056],
>         [-0.1102,  0.2868],
>         [ 0.5256,  1.0619],
>         [ 0.3089, -1.1999],
>         [ 1.7095, -0.1745],
>         [ 1.4144, -0.3567]]) 
>  tensor([[ 6.7916],
>         [-2.4605],
>         [-1.1847],
>         [ 2.6828],
>         [ 6.3722],
>         [ 3.0165],
>         [ 1.6411],
>         [ 8.8942],
>         [ 8.2206],
>         [ 8.2646]])



这段代码是一个简单的线性回归模型，用于生成一些合成数据。在这个模型中，我们使用了PyTorch库来生成随机数据。我们首先定义了一个函数`synthetic_data`，它生成了一个包含1000个样本的数据集。然后我们定义了一个函数data_iter，它将数据集分成大小为batch_size的小批量。最后，我们使用`data_iter`函数来打印第一个小批量的特征和标签。

yield语句是Python中用于生成器函数的关键字。它可以将函数变成一个生成器，生成器每次产生一个值（yield语句），函数被冻结，被唤醒后再产生一个值。而return语句则是返回结果后结束函数的运行.























