# 数据预处理

[TOC]



## 1 读取数据集

### 1.1 创建数据集

首先创建一个数据集“house_tiny.csv”：

```python
import os
import pandas as pd

os.makedirs(os.path.join('..', 'data'), exist_ok=True)
data_file = os.path.join('..', 'data', 'house_tiny.csv')
with open(data_file, 'w') as f:
    f.write('NumRooms,Alley,Price\n')  # 列名
    f.write('NA,Pave,127500\n')  # 每行表示一个数据样本，“NA”项代表缺失值
    f.write('2,NA,106000\n')
    f.write('4,NA,178100\n')
    f.write('NA,NA,140000\n')
```

逐行解释：

```python
os.makedirs(os.path.join('..', 'data'), exist_ok=True)
```

  在这段代码中，`os.makedirs()`方法用于递归创建目录。具体来说，它接受两个参数：要创建的目录路径和目录权限模式。在这里，第一个参数是"../data"，表示"data"文件夹将被创建在当前文件夹的上一级目录中。第二个参数`exist_ok=True`表示，如果"data"文件夹已经存在，不会引发异常，如果"data"文件夹不存在，它将被创建。



```python
data_file = os.path.join('..', 'data', 'house_tiny.csv')
```

  这里的`os.path.join()`方法接受多个参数，可以将多个路径组合成一个路径字符串。在这里，它接受三个参数：`".."`，表示当前文件夹的上一级目录；`"data"`，表示要创建的目录；`"house_tiny.csv"`，表示数据文件名。因此，`os.path.join('..', 'data', 'house_tiny.csv')`将返回一个字符串，表示完整的数据文件路径。



```python
with open(data_file, 'w') as f:
```

  这里使用`open()`函数创建一个新文件对象`f`，并将其指定为写模式。在这里，数据文件名为`"house_tiny.csv"`，模式为`w`，表示写模式。这意味着如果数据文件不存在，将创建一个新文件；如果数据文件已经存在，将**覆盖**原文件。

此时目录下会出现刚刚创建完的文件：

<img src="https://img-blog.csdnimg.cn/9429f7d875834e75a1efe0df0a795947.png" style="zoom:67%;" />

打开内容：

<img src="https://img-blog.csdnimg.cn/2be8bcbc34f649dabeb69975cda45246.png" style="zoom:33%;" />



### 1.2 读取数据集

```python
data = pd.read_csv(data_file)  # 注意要导入panda库
print(data)
```

输出结果：

> ```python
>    NumRooms Alley   Price
> 0       NaN  Pave  127500
> 1       2.0   NaN  106000
> 2       4.0   NaN  178100
> 3       NaN   NaN  140000
> ```
>
> 注意读取数据集的同时，数据集不能呈打开(正在浏览)的状态，否则会发生报错。



### 1.3 处理缺失值

 对于“NAN”这些**`缺失数据`**，典型的方法包括**`插值法`**和**`删除法`**， 其中插值法**用一个替代值弥补缺失值**，而删除法则**直接忽略缺失值**。 在这里，我们将考虑插值法。

这里首先通过位置索引`iloc`，将`data`分成`inputs`和`outputs`， 其中前者为`data`的前两列，而后者为`data`的最后一列。 

```python
inputs, outputs = data.iloc[:, 0:2], data.iloc[:, 2] # 注：":"表示所有列， "0:2"表示第0列到第1列(左闭右开)
print(inputs)
print(outputs)
```

输出结果：

>    NumRooms Alley
> 0       NaN  Pave
> 1       2.0   NaN
> 2       4.0   NaN
> 3       NaN   NaN
> 0    127500
> 1    106000
> 2    178100
> 3    140000
> Name: Price, dtype: int64

注：末尾行的`Name: Price, dtype: int64`是怎么来的：当从CSV文件中读取数据时，Pandas库会自动添加这些信息。



对于输入数据中的类别值或离散值，通过使用Pandas库中的`get_dummies()`方法，可以将类别值转换为[虚拟变量](####1.3.1 虚拟变量)，以便于机器学习算法进行处理。

```python
inputs, outputs = data.iloc[:, 0:2], data.iloc[:, 2]
inputs = pd.get_dummies(inputs, dummy_na=True)  # 将"NA"转换为虚拟变量
# inputs = inputs.astype('float32')  # 将数据类型转换为float32，输出就是0,1,而不是True和False了
print(inputs)
```

输出结果：

>    NumRooms  Alley_Pave  Alley_nan
> 0       NaN        True      False
> 1       2.0       False       True
> 2       4.0       False       True
> 3       NaN       False       True

详细解释一下上述过程：

  通过使用Pandas库中的`get_dummies()`方法，会自动将某一列转换为多列。例如，在处理“Alley”列时，Pandas库会自动将这一列的类别值“Pave”和“NaN”转换为两列“Alley_Pave”和“Alley_nan”，其中“Alley类型”中为“Pave”的行会将“Alley_Pave”的值设置为1(True)，“Alley_nan”的值设置为0(False)，缺少“Alley类型”的行会将“Alley_Pave”和“Alley_nan”分别设置为0和1。



接下来将第一列的两个NaN项进行替换，即使用同一列的均值替换“NaN”项

```python
inputs = inputs.fillna(inputs.mean())  # 用同一列的均值替换“NaN”项
```

输出结果：

>    NumRooms  Alley_Pave  Alley_nan
> 0       3.0        True      False
> 1       2.0       False       True
> 2       4.0       False       True
> 3       3.0       False       True



#### 1.3.1 虚拟变量

  **虚拟变量（dummy variable）**是一种用于表示分类数据的数字变量，通常用于将包含类别值或离散值的变量转换为数字变量，以便在后续的模型训练中使用。虚拟变量通常采用**二元编码（binary encoding）**的方式进行表示，即将每个类别映射为一个**二元组（0，1）**，其中1表示该类别存在，0表示该类别不存在。这种编码方式可以有效地避免数字编码（numeric encoding）中出现的大小关系和算术操作等问题，同时也可以提高模型的鲁棒性和泛化能力。

  在实际应用中，虚拟变量通常使用**One-Hot编码（独热编码）**实现。具体来说，对于一个包含m个类别的变量，可以将其转换为m个虚拟变量，每个虚拟变量表示一个类别，并且只有在该类别出现时才为1，否则为0。例如，对于一个包含颜色类别的变量，可以将其转换为三个虚拟变量“红色”、“绿色”和“蓝色”，其中只有在颜色为“红色”时，“红色”虚拟变量的值为1，而其他虚拟变量的值都为0。

  总之，虚拟变量是一种用于表示分类数据的数字变量，通常采用二元编码的方式进行表示，以便在后续的模型训练中使用。虚拟变量可以避免数字编码中出现的问题，同时也可以提高模型的鲁棒性和泛化能力。



#### 1.3.2 为什么要将空值视为一个独立的类别

  将空值视为一个独立的类别的主要原因是避免在数据预处理过程中出现数据丢失的情况。在实际应用中，往往会遇到一些包含类别值或离散值的数据，例如性别、颜色、区域等等，而这些数据中可能会存在一些缺失值或空值，例如未知、未填写等等。如果直接将这些缺失值或空值删除或填充为其他值，可能会导致数据集的大小或分布发生改变，从而影响模型的性能。

  因此，将空值视为一个独立的类别，可以在保留所有数据的同时，避免数据处理过程中出现数据丢失的情况。具体来说，可以使用**虚拟变量**的方式将包含空值的类别变量转换为数字变量，从而可以在后续的模型训练中使用。在转换过程中，所有的非空值取值会被映射为一个二元组（0，1），其中1表示该值存在，0表示该值不存在；而所有的空值则会被映射为一个三元组（0，0，1），其中1表示该值为空，0表示该值不存在。

  总之，将空值视为一个独立的类别可以避免数据丢失和数据偏差的问题，同时也可以提高模型的鲁棒性和泛化能力。在具体应用中，应根据数据的实际情况选择合适的方法进行处理，以便获得更好的模型效果。



### 1.4 转化为张量格式

现在准备将`inputs`和`outputs`转换为张量格式。

我们先要了解何种数据类型可以直接使用`torch.tensor`方法来转换成张量。通过查阅手册可以知道，只有`float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool`类型可以通过直接使用`torch.tensor`方法来转换成张量。

接下来我们来查看下`inputs`和`outputs`是否满足能直接转换的条件：

```python
inputs= data.iloc[:, 0:2]
outputs = data.iloc[:, 2]

print('inputs:')
print(inputs.dtypes, end='\n\n')  # 使用dtype而非type来访问数据元素类型，因为前者更适用于pandas库
print('outputs:')
print(outputs.dtypes)
```

输出结果：

> inputs:
> NumRooms    float64
> Alley        object
> dtype: object
>
> outputs:
> int64

  观察结果可以发现，`inputs`的`dtype`是`object`的，故其不可以直接使用`torch.tensor`方法来转换成张量(否则会报错)，而`outputs`的`dtype`是`int64`的，满足直接转化的条件。

为什么inputs是object类型的呢？因为初始数据元素有bool有float64，只要有不同元素出现，整体数据类型(dtype)就是object类型

因此我们在其中添加一句`inputs = inputs.astype('float64')`

即可将`inputs`转化为可直接转化为张量的类型。

最终代码：

```python
inputs= data.iloc[:, 0:2]
outputs = data.iloc[:, 2]

inputs = pd.get_dummies(inputs, dummy_na=True)  # 将"NA"转换为虚拟变量
inputs = inputs.fillna(inputs.mean())  # 用同一列的均值替换“NaN”项

print(inputs.dtypes) # 此时是object类型，因为数据元素有bool有float64，
# 只要有不同元素出现，整体数据类型(dtype)就是object类型

X = torch.tensor(inputs.values)
y= torch.tensor(outputs.values)
print('X:')
print(X, end='\n\n')
print('y:')
print(y)
```

输出结果：

> NumRooms      float64
> Alley_Pave       bool
> Alley_nan        bool
> dtype: object
> X:
> tensor([[3., 1., 0.],
>         [2., 0., 1.],
>         [4., 0., 1.],
>         [3., 0., 1.]], dtype=torch.float64)
>
> y:
> tensor([127500, 106000, 178100, 140000])



## 2 练习

1. 删除缺失值最多的列。
2. 将预处理后的数据集转换为张量格式。

### 2.1 删除缺失值最多的列

要删除缺失值最多的列，首先需要读取CSV文件中的数据，并找到缺失值最多的列。在Python中，可以使用pandas库来读取CSV文件，然后使用isnull()函数来检查数据中的缺失值数量。最后，使用drop()函数来删除缺失值最多的列。

以下是代码示例：

```python
import pandas as pd

# 读取CSV文件
data_file = '../data/house_tiny.csv'
data = pd.read_csv(data_file)

# 计算每列缺失值数量
missing_counts = data.isnull().sum()

# 找到缺失值最多的列
max_missing_count = missing_counts.max()
max_missing_col = missing_counts.idxmax()

# 删除缺失值最多的列
data = data.drop(columns=[max_missing_col])
```

该代码首先使用pandas库中的read_csv()函数读取CSV文件中的数据。接下来，使用isnull()函数计算每列数据中的缺失值数量，然后使用sum()函数对结果进行求和。最后，使用idxmax()函数和max()函数找到缺失值数量最多的列，并使用drop()函数删除该列。



### 2.2 将预处理后的数据集转换为张量格式

要将预处理后的数据集转换为张量格式，可以使用PyTorch库。PyTorch是一个用于科学计算的开源库，其中包含了用于构建深度神经网络的工具。将数据集转换为张量格式后，可以使用PyTorch中的数据加载器来加载数据并进行训练。

以下是代码示例：

```python
import torch
import pandas as pd

# 读取CSV文件
data_file = '../data/house_tiny.csv'
data = pd.read_csv(data_file)

# 删除缺失值最多的列
missing_counts = data.isnull().sum()
max_missing_count = missing_counts.max()
max_missing_col = missing_counts.idxmax()
data = data.drop(columns=[max_missing_col])

# 将数据集转换为张量格式
data_array = data.values.astype('float32')
features = torch.from_numpy(data_array[:, 0:2])
labels = torch.from_numpy(data_array[:, 2])

# 创建数据加载器
batch_size = 2
dataset = torch.utils.data.TensorDataset(features, labels)
data_iter = torch.utils.data.DataLoader(dataset, batch_size, shuffle=True)
```

该代码首先使用pandas库中的read_csv()函数读取CSV文件中的数据。接下来，使用之前提到的方法删除缺失值最多的列。然后，使用values属性将数据集转换为NumPy数组，并使用astype()函数将数组中的值转换为32位浮点数。最后，使用from_numpy()函数将NumPy数组转换为PyTorch张量。

在将数据集转换为张量格式后，可以使用PyTorch中的TensorDataset和DataLoader来创建数据加载器。TensorDataset将特征和标签组合成一个数据集，而DataLoader则用于将数据集划分为小批量数据，并对数据进行随机排序。

总之，要删除缺失值最多的列，可以使用pandas库中的isnull()函数和drop()函数。要将预处理后的数据集转换为张量格式，可以使用PyTorch库中的Tensor和DataLoader。





## 3 小结

  总之，本节介绍了如何使用Pandas库来处理缺失值，包括用同一列的均值替换NaN项和将类别值转换为虚拟变量，以便于机器学习算法进行处理。同时，还介绍了Pandas库自动将某一列转换为多列的方法，以便于更好地处理数据集中的缺失值。









